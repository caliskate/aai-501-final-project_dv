{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7603809c-1f4d-4dcd-bf23-1b7f20c86393",
   "metadata": {},
   "source": [
    "# Video Recognition exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31d505-37b7-4209-b20f-689cdd6645ac",
   "metadata": {},
   "source": [
    "## Configuring the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a026eabd-d615-4414-9f9b-74d5df01e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import math \n",
    "import os # file \n",
    "\n",
    "# MODEL loading and config\n",
    "# model\n",
    "model = YOLO(\"../models/best_from_darin.pt\")\n",
    "\n",
    "class_names = ['Hardhat','Mask','NO-Hardhat',\n",
    "              'NO-Mask','NO-Safety Vest','Person',\n",
    "              'Safety Cone','Safety Vest','Machinery','Vehicle']\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"../datasets/stream_result\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976bec14-17c3-4b54-8228-a3c8516a5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRAWING METHODS\n",
    "\n",
    "# Function to get class colors\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
    "    color = [base_colors[color_index][i] + increments[color_index][i] * \n",
    "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
    "    return tuple(color)\n",
    "\n",
    "\n",
    "def drawPredictions(predictions, img, class_names): \n",
    "    for p in predictions:\n",
    "        boxes = p.boxes\n",
    "        for box in boxes:\n",
    "            if box.conf[0] > 0.4:\n",
    "                # get coordinates\n",
    "                [x1, y1, x2, y2] = box.xyxy[0]\n",
    "                # convert to int\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "                cls = int(box.cls[0]) # get the class index\n",
    "        \n",
    "                colour = getColours(cls)\n",
    "        \n",
    "                # draw prediction the rectangle\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), colour, 2)\n",
    "        \n",
    "                # put the class name and confidence on the image\n",
    "                cv2.putText(img, f'{class_names[cls]} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "\n",
    "\n",
    "def predict_video_stream(camera, output, verbose=False, showWindow=True, flipImage=False):\n",
    "    while True:\n",
    "        ret, frame = camera.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if flipImage:\n",
    "            frame = cv2.flip(frame, 1)  \n",
    "            \n",
    "        results = model(frame, stream=True, verbose=False)\n",
    "        drawPredictions(results, frame, class_names)\n",
    "        \n",
    "        # Write the frame to the output file\n",
    "        output.write(frame)\n",
    "        # Display the captured frame - Performance changes when not showing\n",
    "        if showWindow:\n",
    "            cv2.imshow('Camera', frame)\n",
    "    \n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae519a-fb0b-42c5-8bc6-bcefb3381579",
   "metadata": {},
   "source": [
    "## Capture Livestream Video from webcam\n",
    "\n",
    "### Use 'q' to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e88b89-7c1f-4c4a-9df3-bf784ad85763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 11:34:10.170 python3[52561:3324672] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2024-11-25 11:34:12.738 python3[52561:3324672] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-25 11:34:12.738 python3[52561:3324672] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the default camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('../dataset/stream_result/output_webcam.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "# START PREDICTION AND PRESENTATION\n",
    "predict_video_stream(cam, out, verbose=False, showWindow=True, flipImage=True)\n",
    "\n",
    "\n",
    "# Release the capture and writer objects\n",
    "cam.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834af0d-36d9-4b18-8e5c-c80be1812a5c",
   "metadata": {},
   "source": [
    "# Analyzing Video File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af6f213-a5d6-4c1c-a90e-6e336b2efc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 11:27:27.777 python3[52297:3316469] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-25 11:27:27.777 python3[52297:3316469] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the default camera\n",
    "cam = cv2.VideoCapture(\"../datasets/custom_ppe_videos/scene1.mp4\")\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('../datasets/stream_result/output_custom_video.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "# START PREDICTION AND PRESENTATION\n",
    "predict_video_stream(cam, out, verbose=False, showWindow=True)\n",
    "\n",
    "\n",
    "# Release the capture and writer objects\n",
    "cam.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "masters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
