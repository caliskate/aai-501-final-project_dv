{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b09734a-b21e-4b24-ac26-f6999011dded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Using cached albumentations-1.4.21-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (1.14.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (2.8.2)\n",
      "Collecting albucore==0.0.20 (from albumentations)\n",
      "  Using cached albucore-0.0.20-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting eval-type-backport (from albumentations)\n",
      "  Using cached eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albucore==0.0.20->albumentations) (3.10.10)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albucore==0.0.20->albumentations) (6.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\darin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n",
      "Using cached albumentations-1.4.21-py3-none-any.whl (227 kB)\n",
      "Using cached albucore-0.0.20-py3-none-any.whl (12 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: opencv-python-headless, eval-type-backport, albucore, albumentations\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\DARiN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2446e720-c43a-4c2e-b9d0-66cb1ec1a659",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO \u001b[38;5;66;03m#for obeject detection\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m \u001b[38;5;66;03m# for image augmentation\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensorV2 \u001b[38;5;66;03m# for image formating\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import os # file \n",
    "import shutil\n",
    "import cv2 # opencv for images\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ultralytics import YOLO #for obeject detection\n",
    "import albumentations as A # for image augmentation\n",
    "from albumentations.pytorch import ToTensorV2 # for image formating\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9771bb-799a-4507-ad5a-a47209f38615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get class colors\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
    "    color = [base_colors[color_index][i] + increments[color_index][i] * \n",
    "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
    "    return tuple(color)\n",
    "\n",
    "\n",
    "def drawPredictions(predictions, img): \n",
    "    for p in predictions:\n",
    "        boxes = p.boxes\n",
    "        for box in boxes:\n",
    "            if box.conf[0] > 0.4:\n",
    "                # get coordinates\n",
    "                [x1, y1, x2, y2] = box.xyxy[0]\n",
    "                # convert to int\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "                cls = int(box.cls[0]) # get the class index\n",
    "                # get the class name\n",
    "                class_name = cls\n",
    "        \n",
    "                colour = getColours(cls)\n",
    "        \n",
    "                # draw prediction the rectangle\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), colour, 2)\n",
    "        \n",
    "                # put the class name and confidence on the image\n",
    "                cv2.putText(img, f'{cls} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "                #cv2.putText(img, f'{classNames[int(box.cls[0])]} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad724633-8659-4729-9af5-c82ccebe4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load YOLOv8 pre-trained model\n",
    "model = YOLO(\"../models/yolov8n.pt\")\n",
    "\n",
    "#Manually presenting annotations \n",
    "\n",
    "\n",
    "# train files\n",
    "base_dir=\"../datasets/images/train/\"\n",
    "\n",
    "image_files=[\"-2544-_png_jpg.rf.13bfe27776b4d713faf93d42421ae13f.jpg\", \n",
    "             \"-2544-_png_jpg.rf.185d1d1c0cb4027d76f7e31cd409022e.jpg\",\n",
    "             \"-2544-_png_jpg.rf.1224ec786928243a0076833c5ddb34f4.jpg\",\n",
    "            \"616_jpg.rf.440e1d2885969b920d1115e4dd9c95d3.jpg\",\n",
    "            \"2008_008600_jpg.rf.1e30fdd484a479256bd540cc92dc375b.jpg\",\n",
    "            \"2008_008618_jpg.rf.36f88cd9160d2a0be857a1f22210540b.jpg\",\n",
    "            \"2009_000280_jpg.rf.7c269bca3935b65ae9bf2d15593b9711.jpg\",\n",
    "            \"amz_02354_png_jpg.rf.05804b93377b6f8d38b6e61553c4c129.jpg\",\n",
    "            \"autox6_mp4-80_jpg.rf.0cebdad4d9d8f205f998ceaad09ea576.jpg\"]\n",
    "\n",
    "for path in image_files:\n",
    "    # Open image file for reading and fix color grading\n",
    "    file = base_dir + path\n",
    "    print(file)\n",
    "    img = cv2.imread(file) \n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # perform inference using YOLOv8\n",
    "    results = model(img)\n",
    "    \n",
    "    drawPredictions(results, img)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
